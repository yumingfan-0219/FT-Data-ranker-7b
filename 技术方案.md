1.运行环境和开源模型
该代码的运行环境与竞赛所要求的环境完全一致，具体要求请查看竞赛页面上的原始提交指南。
同时，该代码使用QWen-14b模型进行数据增强操作，具体而言，我们的操作将top-p参数和temp参数都设为0，一定程度上去除了随机性。
如需复现，需要下载该模型，下载方式可参考https://modelscope.cn/models/qwen/Qwen-14B-Chat/summary
2.方案综述
本方案旨在通过数据增强来提高测试数据集上的摘要任务性能。针对测试数据显示的摘要任务能力不足，我们计划将问答数据转换为摘要形式，从而在不直接增加原始训练数据量的前提下，间接扩充训练集。
通过这种方法，我们预期能够生成一个数据丰富、多样化的摘要任务训练集。这将有助于模型更好地学习和理解摘要任务的要求，从而在测试数据集上展现出更强的性能。
简而言之，我们的方案的思想在于针对具体任务构造对应的微调数据，作为一种新颖的数据增强方式。
3.总体实现流程
英文数据集处理：
首先，我们对原始英文数据集（raw_data_en）进行预处理。该过程分为两个主要步骤，依序执行两个配置文件的处理指令。初始步骤采用 bloom-oscar.yaml 配置，接着使用 redpajama-c4-refine.yaml 进行进一步的细化处理。这一连串处理的结果是中间数据集 train-bloom-c4.json。
数据任务转换尝试：
在分析测试数据后，我们注意到模型在文本摘要任务上的性能不尽人意。为了改善这一状况，我们考虑将问答数据转换为摘要形式。这一过程利用了 qwen-14b 开源模型对 train-bloom-c4.json 进行推理，同时融入了关于摘要任务的提示（prompt）。在这一步骤中，我们严格遵守了官方的参数设置要求，确保 top-p 和 temperature 参数均设置为1。我们首先使用详细的实现代码见 FT-Data-Ranker-7b-code-model/code-data/data/construct_data.py 和 FT-Data-Ranker-7b-code-model/code-data/competition_kit/qwen-infer.py，其中前者用于构造prompt数据，后者基于这份prompt数据生成结果。
新增数据生成：
通过上述处理，我们成功生成了约1万条新的文本摘要主题相关的问答对数据。这些数据被保存在 competition_kit/data/raw_data/train_bloom-c4-summ.jsonl。
训练数据集的最终组合：
结合新生成的 train_bloom-c4-summ.jsonl 数据和原有的英文、中文数据，我们构建了最终的训练数据集 train_bloom-c4-qwen14b-1w-summ.json。这个数据集包含了大约1.5M token，其中包括了1万条新生成的摘要类型数据。数据集的构建过程详见 FT-Data-Ranker-7b-code-model/code-data/competition_kit/lm-training/get_train_dataset_7b.py。
接下来的步骤与阶段1相同。
中文数据集处理：
对于中文数据集，我们采用了相同文件夹中的 alpaca 配置文件进行处理。
数据采样策略：
在数据采样阶段，我们设计了一系列针对特定关键词的硬匹配采样策略。这些策略的具体实现可在 competition_kit/lm-training/get_train_dataset_7b.py 中找到。我们同时确保了最终训练集的 token 数量保持一致。
训练数据集的确定：
所有训练相关的数据集均存放于 data 文件夹中。
训练参数设置：
在训练过程中，我们没有对训练参数进行任何更改。
推理过程的设置：
在模型推理阶段，我们选择使用 fp32 精度以确保结果的准确性。