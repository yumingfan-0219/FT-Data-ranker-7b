## 1. 运行环境和开源模型

本代码的运行环境与竞赛要求的环境一致，详细环境配置可参见[官方竞赛页面](https://tianchi.aliyun.com/competition/entrance/532158)的原始提交指南。

我们使用了 QWen-14b 模型进行数据增强操作。具体来说，为了减少随机性，我们将 `top-p` 和 `temp` 参数都设为 0。若需复现，请参考 [QWen-14B-Chat 模型下载](https://modelscope.cn/models/qwen/Qwen-14B-Chat/summary)。

## 2. 方案综述

本方案通过数据增强提高测试数据集上的摘要任务性能。考虑到测试数据显示的摘要任务能力不足，我们将问答数据转换为摘要形式，从而间接扩充训练集。目的是创建一个数据丰富、多样化的摘要任务训练集，以帮助模型更好地学习和理解摘要任务要求，进而在测试数据集上表现出更强的性能。

## 3. 总体实现流程

### 英文数据集处理：

- **预处理**：对原始英文数据集 `raw_data_en` 进行预处理，包括两个步骤：使用 `bloom-oscar.yaml` 和 `redpajama-c4-refine.yaml` 进行处理。
- **结果**：生成中间数据集 `train-bloom-c4.json`。

### 数据任务转换尝试：

- **处理过程**：使用 qwen-14b 模型对 `train-bloom-c4.json` 进行推理，融入摘要任务的提示。
- **实现代码**：见 `FT-Data-Ranker-7b-code-model/code-data/data/construct_data.py` 和 `FT-Data-Ranker-7b-code-model/code-data/competition_kit/qwen-infer.py`。

### 新增数据生成：

- **输出**：生成约1万条新的文本摘要主题相关问答对数据，保存在 `competition_kit/data/raw_data/train_bloom-c4-summ.jsonl`。

### 训练数据集的最终组合：

- **构建过程**：结合新生成的数据和原有的英文、中文数据，构建最终训练集 `train_bloom-c4-qwen14b-1w-summ.json`。
- **细节**：详见 `FT-Data-Ranker-7b-code-model/code-data/competition_kit/lm-training/get_train_dataset_7b.py`。

### 中文数据集处理：

- **处理方式**：使用同一文件夹中的 `alpaca` 配置文件。

### 数据采样策略：

- **实现方式**：设计针对特定关键词的硬匹配采样策略，实现见 `competition_kit/lm-training/get_train_dataset_7b.py`。

### 训练参数设置：

- **配置**：在训练过程中，未对训练参数进行更改。

### 推理过程的设置：

- **推理方式**：在模型推理阶段，选择使用 fp32 精度确保结果准确性。
